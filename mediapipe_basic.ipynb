{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy1SOyGH3SrK"
      },
      "source": [
        "## 1. Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pieasls4zF5C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in c:\\users\\gandr\\anaconda3\\lib\\site-packages (0.10.10)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (22.10.26)\n",
            "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: jax in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.7)\n",
            "Requirement already satisfied: opencv-contrib-python in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
            "Requirement already satisfied: numpy in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.4)\n",
            "Requirement already satisfied: absl-py in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (2.1.0)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.14.5)\n",
            "Requirement already satisfied: pycparser in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.20)\n",
            "Requirement already satisfied: opt-einsum in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.7.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.3.0)\n",
            "Requirement already satisfied: six in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\gandr\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\gandr\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hvz9I6Sh4In1"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "#from google.colab.patches import cv2_imshow\n",
        "import uuid # Para generar ids unicos\n",
        "import os "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUSXdHR3q-E"
      },
      "source": [
        "## 2. Deteccion de Manos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y9qw4Pno4qX0"
      },
      "outputs": [],
      "source": [
        "# Permite renderizar las salidas de los puntos de la mano\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "# Modelo de manos\n",
        "mp_hands = mp.solutions.hands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by8OQWhA70SG"
      },
      "source": [
        "### Deteccion de manos con Webcam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIbEbN8-7xR6"
      },
      "source": [
        "Presionar q para salir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g97kvgrz40gK"
      },
      "outputs": [],
      "source": [
        "# Webcam feed, usamos el dispositivo 0 de captura, puede ser diferente\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Instanciamos el modelo de las manos, detection y tracking son los dos modelos que se usan\n",
        "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5, max_num_hands=2) as hands:\n",
        "  # Mientas estamos conectados a la webcam\n",
        "  while cap.isOpened():\n",
        "    # Leemos cada cuadro, no usamos ret, frame es el cuadro\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    #DETECCION CON MEDIAPIPE\n",
        "    # Recoloreamos el feed obtenido de cv2 de BGR a RGB para usarlo en mediapipe\n",
        "    image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "    #Invertimos la imagen de manera horizontal, para detectar de manera correcta cual mano es derecha y cual izquierda\n",
        "    image = cv2.flip(image,1)\n",
        "    # Evita que podamos dibujar sobre la imagen\n",
        "    image.flags.writeable = False\n",
        "    # Realizamos la deteccion\n",
        "    results = hands.process(image)\n",
        "    # Nos permite dibujar sobre la imagen de nuevo\n",
        "    image.flags.writeable = True\n",
        "\n",
        "    # Convertimos de RGB a BGR\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "    # print(results)\n",
        "\n",
        "    # Renderizar los resultados si detecta akgi (en la variable results)\n",
        "    if results.multi_hand_landmarks:\n",
        "      for num, hand in enumerate(results.multi_hand_landmarks):\n",
        "        mp_drawing.draw_landmarks(image,hand, mp_hands.HAND_CONNECTIONS,\n",
        "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
        "                                  mp_drawing.DrawingSpec(color=(224, 224, 224), thickness=2, circle_radius=2))\n",
        "\n",
        "    # Mostramos frame\n",
        "    cv2.imshow('Hand Tracking', image)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejemplos de datos obtenidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "multi_hand_landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[landmark {\n",
            "  x: 0.6046357154846191\n",
            "  y: 0.8187534213066101\n",
            "  z: 4.4169800617055444e-07\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5402639508247375\n",
            "  y: 0.7942764759063721\n",
            "  z: -0.02468423917889595\n",
            "}\n",
            "landmark {\n",
            "  x: 0.4876232147216797\n",
            "  y: 0.7256060242652893\n",
            "  z: -0.03511936590075493\n",
            "}\n",
            "landmark {\n",
            "  x: 0.4490585923194885\n",
            "  y: 0.6730635166168213\n",
            "  z: -0.0437522828578949\n",
            "}\n",
            "landmark {\n",
            "  x: 0.41153767704963684\n",
            "  y: 0.6478210687637329\n",
            "  z: -0.052935026586055756\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5338413715362549\n",
            "  y: 0.5960366725921631\n",
            "  z: -0.017761103808879852\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5109515190124512\n",
            "  y: 0.5127018690109253\n",
            "  z: -0.03300157189369202\n",
            "}\n",
            "landmark {\n",
            "  x: 0.4975605607032776\n",
            "  y: 0.45701584219932556\n",
            "  z: -0.04694559425115585\n",
            "}\n",
            "landmark {\n",
            "  x: 0.48792821168899536\n",
            "  y: 0.4091030955314636\n",
            "  z: -0.058943480253219604\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5768252611160278\n",
            "  y: 0.5835236310958862\n",
            "  z: -0.021877290681004524\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5759693384170532\n",
            "  y: 0.4844900965690613\n",
            "  z: -0.03422805666923523\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5761561989784241\n",
            "  y: 0.42133790254592896\n",
            "  z: -0.04724527895450592\n",
            "}\n",
            "landmark {\n",
            "  x: 0.5763164758682251\n",
            "  y: 0.3684994578361511\n",
            "  z: -0.057874370366334915\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6163660287857056\n",
            "  y: 0.5960114598274231\n",
            "  z: -0.03008885122835636\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6239330768585205\n",
            "  y: 0.5027050375938416\n",
            "  z: -0.04883737862110138\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6271297931671143\n",
            "  y: 0.4416544437408447\n",
            "  z: -0.06483587622642517\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6292060017585754\n",
            "  y: 0.38369467854499817\n",
            "  z: -0.07697860896587372\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6524448990821838\n",
            "  y: 0.6283453702926636\n",
            "  z: -0.04042009636759758\n",
            "}\n",
            "landmark {\n",
            "  x: 0.6813908815383911\n",
            "  y: 0.5718686580657959\n",
            "  z: -0.06156453490257263\n",
            "}\n",
            "landmark {\n",
            "  x: 0.7005279660224915\n",
            "  y: 0.5305793285369873\n",
            "  z: -0.07331141084432602\n",
            "}\n",
            "landmark {\n",
            "  x: 0.716709315776825\n",
            "  y: 0.4873150587081909\n",
            "  z: -0.08162347972393036\n",
            "}\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(results.multi_hand_landmarks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HAND_CONNECTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "frozenset({(0, 1),\n",
              "           (0, 5),\n",
              "           (0, 17),\n",
              "           (1, 2),\n",
              "           (2, 3),\n",
              "           (3, 4),\n",
              "           (5, 6),\n",
              "           (5, 9),\n",
              "           (6, 7),\n",
              "           (7, 8),\n",
              "           (9, 10),\n",
              "           (9, 13),\n",
              "           (10, 11),\n",
              "           (11, 12),\n",
              "           (13, 14),\n",
              "           (13, 17),\n",
              "           (14, 15),\n",
              "           (15, 16),\n",
              "           (17, 18),\n",
              "           (18, 19),\n",
              "           (19, 20)})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mp_hands.HAND_CONNECTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![hands](resource/img/hand-landmarks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.mkdir('Output_images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta version del codigo guarda cada cuadro de la imagen dentro de un folder local ('Output_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Webcam feed, usamos el dispositivo 0 de captura, puede ser diferente\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Instanciamos el modelo de las manos, detection y tracking son los dos modelos que se usan\n",
        "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5, max_num_hands=2) as hands:\n",
        "  # Mientas estamos conectados a la webcam\n",
        "  while cap.isOpened():\n",
        "    # Leemos cada cuadro, no usamos ret, frame es el cuadro\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    #DETECCION CON MEDIAPIPE\n",
        "    # Recoloreamos el feed obtenido de cv2 de BGR a RGB para usarlo en mediapipe\n",
        "    image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "    #Invertimos la imagen de manera horizontal, para detectar de manera correcta cual mano es derecha y cual izquierda\n",
        "    image = cv2.flip(image,1)\n",
        "    # Evita que podamos dibujar sobre la imagen\n",
        "    image.flags.writeable = False\n",
        "    # Realizamos la deteccion\n",
        "    results = hands.process(image)\n",
        "    # Nos permite dibujar sobre la imagen de nuevo\n",
        "    image.flags.writeable = True\n",
        "\n",
        "    # Convertimos de RGB a BGR\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "    # print(results)\n",
        "\n",
        "    # Renderizar los resultados si detecta akgi (en la variable results)\n",
        "    if results.multi_hand_landmarks:\n",
        "      for num, hand in enumerate(results.multi_hand_landmarks):\n",
        "        mp_drawing.draw_landmarks(image,hand, mp_hands.HAND_CONNECTIONS,\n",
        "                                  mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
        "                                  mp_drawing.DrawingSpec(color=(224, 224, 224), thickness=2, circle_radius=2))\n",
        "    \n",
        "    # Para guardar la imagen\n",
        "    cv2.imwrite(\n",
        "      os.path.join(\n",
        "        'Output_images',\n",
        "        '{}.jpg'.format(uuid.uuid1())),\n",
        "        image)\n",
        "    \n",
        "    # Mostramos frame\n",
        "    cv2.imshow('Hand Tracking', image)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ejemplo uuid1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Output_images\\\\f35c6690-d33b-11ee-9aa5-3c58c2bc1ad2.jpg'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(\n",
        "        'Output_images',\n",
        "        '{}.jpg'.format(uuid.uuid1()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
