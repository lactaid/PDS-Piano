{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de Dataset\n",
    "\n",
    "Este notebook se utiliza para la creación del conjunto de datos para el modelo, primero muestreamos fotogramas con las manos en las posiciones deseadas, después, procesamos cada imágen y escribimos los datos en un archivo.\n",
    "\n",
    "Por el momento se ha implementado de manera separado para no realizar procesos adicionales durante el muestreo, pero si demuestra no ser de mucho impacto, se podría implementar como un solo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar en caso de no tenerlo\n",
    "!pip install mediapipe\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "import os\n",
    "import cv2\n",
    "import pickle # Pickle ya es parte de Python en versiones mas nuevas :)\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de imagenes\n",
    "En esta sección, tomamos un video con las muestras del gesto que queremos muestrear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el path donde de van a guardar todas las fotos\n",
    "DATA_DIR = './model/data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(class_number, dataset_size):\n",
    "    # Definimos el directorio, que fue creado en la celda anterior\n",
    "    DATA_DIR = './model/data'\n",
    "\n",
    "    # Inicializamos el metodo de captura de webcam, el parámetro corresponde para el número de dispositivo, tengo entendido que para WINDOWS es 0 y para MAC es 2\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Creamos un directorio para la clase elegida si este no existe ya\n",
    "    class_dir = os.path.join(DATA_DIR, str(class_number))\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    # Encontramos el ultimo archivo guardado dentro del directorio, para guardarlo bajo ese nombre, ej: 1.png\n",
    "    existing_images = os.listdir(class_dir)\n",
    "    if existing_images:\n",
    "        last_image_number = max([int(img.split('.')[0]) for img in existing_images])\n",
    "    else:\n",
    "        # Si no existe, empezamops a contar desde 0\n",
    "        last_image_number = 0\n",
    "\n",
    "    # Empezamos entonces a contar a partir del siguiente disponible\n",
    "    counter = last_image_number + 1\n",
    "\n",
    "    \n",
    "    # Variable usada despues para salir del programa de manera manual\n",
    "    done = False\n",
    "    # Ciclo inicial para determinar si el usuario va a presionar Q o ESC\n",
    "    while counter <= dataset_size + last_image_number:\n",
    "\n",
    "        # Leemos cada cuadro\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Instrucciones en pantalla\n",
    "        cv2.putText(frame, 'Collecting data for class {} - Press \"Q\" to start'.format(class_number),\n",
    "                    (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, 'Press \"Esc\" to exit', (0, frame.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        key = cv2.waitKey(25)\n",
    "        if key == ord('q'): # Confirmamos que queremos seguir con q, entonces rompemos el ciclo actual y vamos al siguiente\n",
    "            break\n",
    "        elif key == 27:  # Si se presiona esc, salimos del programa\n",
    "            done = True\n",
    "            break\n",
    "    \n",
    "    # Iniciamos este ciclo al hacer break del anterior y si done no es verdad\n",
    "    # Ciclo para recolectar datos\n",
    "    while counter <= dataset_size + last_image_number and not done:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        # Espera input, necesario para que no se rompa el codigo\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(class_dir, '{}.jpg'.format(counter)), frame)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    # Liberamos recursos y mandamos mensaje de confirmacion\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Collecting for class {} successful'.format(class_number))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting for class 1 successful\n"
     ]
    }
   ],
   "source": [
    "gesture = 1 \n",
    "size = 100\n",
    "collectData(gesture, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de coordenadas a partir de las muestras\n",
    "\n",
    "En esta parte, usamos mediapipe para obtener las coordenadas de manos de las imágenes anteriores y lo guardamos en un archivo para procesar en el modelo ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el directorio, que fue creado en la celda anterior\n",
    "DATA_DIR = './model/data'\n",
    "\n",
    "# Listas para guardar los datos de cada gesto y su label correspondiente\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Por cada subdirectorio en DATA_DIR\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    # Por cada imagen en el subdirectorio actuial\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        # Lista auxiliar para guardar los datos de cada mano al final\n",
    "        data_aux = []\n",
    "\n",
    "        # Lista para guardar las coordenadas X y Y de cada mano\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        # Convertimos a RGB para procesar con MediaPipe\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Procesamos la imagen con MediaPipe\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "\n",
    "\n",
    "        # Si se detectaron manos en la imagen\n",
    "        if results.multi_hand_landmarks:\n",
    "\n",
    "            # Para cada mano detectada\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Extraemos la coordenada en X y Y de esta y las guardamos en x_ y_\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                # Normalizamos las medidas y las guardamos en data_aux\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            # Guardamos los datos de data_aux en la lista data, y labels se obtiene a partir del nombre del directorio\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "\n",
    "# Guardamos los datos como un archivo tipo Pickle\n",
    "\n",
    "f = open(os.path.join('model', 'data.pickle'), 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
